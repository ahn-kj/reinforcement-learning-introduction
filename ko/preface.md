# 머리말
우리는 처음으로 1979 년 후반에 강화 학습으로 알려진 것에 초점을 맞추기 시작했습니다. 우리는 매사추세츠 대학에서 초기의 프로젝트 중 하나 인 뉴런과 같은 적응 형 요소의 네트워크가 유망한 접근법이 될 수 있다는 아이디어를 되찾기 위해 노력했습니다 인공 적응 지능으로 이 프로젝트는 A. Harry Klopf가 개발 한 "적응 형 시스템의 이단설 이론"을 탐구했습니다. Harry의 연구는 풍부한 아이디어의 원천이었으며, 우리는 그것을 비판적으로 탐구하고 적응 시스템에서의 이전 연구의 오랜 역사와 비교할 수있었습니다. 우리의 과제는 아이디어를 괴롭 히고 그들의 관계와 상대적인 중요성을 이해하는 것이되었습니다. 오늘날까지도 계속되고 있지만, 1979 년에 오랫동안 당연한 것으로 받아 들여지는 가장 단순한 아이디어가 계산상의 관점에서 놀랄만큼 작은 주목을 받았다는 것을 깨닫게되었습니다. 이것은 단순히 무언가를 원하는 학습 시스템의 개념이었으며 환경에서 특수 신호를 최대화하기 위해 행동을 조정했습니다. 이것은 "유교 적"학습 시스템의 개념이었습니다. 또는 우리가 지금 말했듯이, 강화 학습의 아이디어입니다.

다른 사람들과 마찬가지로 우리는 사이버네틱스와 인공 지능 초기에 강화 학습이 철저히 탐구되었다는 느낌을 받았습니다. 그러나 더 면밀한 조사에서, 우리는 그것이 단지 약간 탐구되었다는 것을 발견했다. 강화 학습이 초기 학습 학습 연구의 일부를 명확하게 자극했지만, 대부분의 연구자는 패턴 분류, 감독 학습, 적응 제어와 같은 다른 것들을 연구했거나 학습 학습을 포기한 상태였습니다 전부. 결과적으로, 환경에서 무언가를 얻는 방법을 배우는 것과 관련된 특별 쟁점은 상대적으로 거의 주목을받지 못했습니다. 되돌아 보면이 아이디어에 초점을 맞추는 것이이 연구 분야를 움직이는 중요한 단계였습니다. 이러한 근본적인 아이디어가 아직 완전히 탐구되지 않았다는 것이 인정 될 때까지 보강 학습의 전산 연구에서는 거의 진전이 이루어지지 않을 수 있습니다. 그 이후로이 분야는 먼 길을 걸어 왔고, 여러 방향으로 진화하고 성숙 해 왔습니다. 강화 학습은 점차 기계 학습, 인공 지능 및 신경망 연구에서 가장 활발한 연구 분야 중 하나가되었습니다. 이 분야는 강력한 수학적 토대와 인상적인 응용 분야를 개발했습니다. 강화 학습에 대한 전산 연구는 현재 심리학, 제어 이론, 인공 지능 및 신경 과학과 같은 다양한 분야의 전 세계 수백 명의 활발한 연구자들과 함께 대규모 분야입니다. 특히 중요한 것은 최적 제어 및 동적 프로그래밍 이론과의 관계를 설정하고 발전시키는 공헌이었습니다. 목표를 달성하기 위해 상호 작용에서 배우는 전반적인 문제는 아직 해결되지 않지만 우리의 이해가 크게 향상되었습니다. 우리는 이제 시간적 차이 학습, 동적 프로그래밍 및 함수 근사와 같은 구성 요소 아이디어를 전반적인 문제와 관련하여 일관된 관점으로 배치 할 수 있습니다. 이 책을 쓰는 우리의 목표는 강화 학습의 주요 아이디어와 알고리즘에 대한 명확하고 간단한 설명을 제공하는 것이 었습니다. 우리는 우리의 치료가 모든 관련 분야의 독자들에게 접근 할 수 있기를 원했지만 우리는 이러한 모든 관점을 상세하게 다루지는 못했습니다. 우리의 치료는 심리학, 신경 과학 및 다른 분야와의 연결을 다른 사람에게 또는 다른 시간에 맡기는 인공 지능 및 엔지니어링의 관점을 거의 독점적으로 취합니다. 우리는 또한 강화 학습에 대한 엄격한 공식 치료를하지 않기로 결정했습니다. 가능한 한 높은 수준의 수학적 추상화를 달성하지 못했고 이론적 증거 형식에 의존하지 않았습니다. 우리는 근본적인 아이디어의 단순성과 잠재적 인 보편성에서 벗어나지 않고 수학적으로 올바른 방향으로 기울어 진 수학적 세부 수준을 선택하려고했습니다.

이 책은 세 부분으로 구성되어 있습니다. 제 1 부는 소개 및 문제 제기입니다. 우리는 보강 학습의 가장 단순한 측면과 주요 특징을 중점적으로 다룹니다. 하나의 전체 장은 우리가 나머지 책에서 탐구하는 해결책 인 보강 학습 문제를 소개하는 데 전념합니다. 2 부는 활동 값을 추정하는 것에 기초한 모든 기본 해법의 표본 버젼 (작은 유한 상태 공간을 가정)을 제시한다. 동적 프로그래밍, 몬테 카를로 방법, 시간차 학습을 소개합니다. 후자의 두 가지 방법을 통합하는 자격 추적에 대한 장과 계획 방법 (예 : 동적 프로그래밍 및 상태 공간 검색)과 학습 방법 (예 : 몬테 카를로 및 시간차 학습)을 통합하는 장이 있습니다. 3 부는 함수 근사법, 정책 구배 방법 및 정책 외 학습 문제 해결을위한 방법을 포함하는 다양한 형태의 근사를 포함하여 표 방법을 확장하는 것에 관한 것이다. 4 부는 생물학 및 응용에서 보강 학습의 최전선을 조사한다.
이 책은 한 학기 코스에서 텍스트로 사용되거나 문학이나 Bertsekas and Tsitsiklis (1996) 또는 Szepesvari와 같은 좀 더 수학적인 텍스트로 읽음으로써 보충 될 수 있도록 고안되었습니다. 이 책은 기계 학습, 인공 지능 또는 신경망에 대한 광범위한 교육 과정의 일부로 사용할 수도 있습니다. 이 경우, 재료의 서브 세트만을 커버하는 것이 바람직 할 수있다. 섹션 3.4, 3.5 및 3.9를 제외한 제 2 장에서 제 2.2 절, 제 3 장, 그리고 시간과 관심에 따라 나머지 장에서 섹션을 선택하는 간단한 개요는 1 장을 다루는 것이 좋습니다. 파트 II의 다섯 장은 서로를 기반으로하며 가장 잘 다룹니다. 이 중 6 장은 주제와 나머지 책에서 가장 중요합니다. 기계 학습이나 신경망에 초점을 맞춘 코스는 9 장을 다루어야하고, 인공 지능이나 계획에 초점을 맞춘 코스는 8 장을 다루어야합니다.이 책 전체에서 책의 나머지 부분에서는 더 어렵고 필수적이지 않은 섹션이 표시되어 있습니다 *로. 나중에 문제를 만들지 않고 첫 번째 읽기에서 생략 할 수 있습니다. 일부 사례는 *로 표시되어 그 내용이 더 발전되어 있고 장의 기초 자료를 이해하는 데 필수적이지는 않다는 것을 나타냅니다.

이 책은 대부분 자체적으로 포함되어 있습니다. 가정 된 유일한 수학적 배경은 확률 변수의 기대치와 같은 확률의 기본 개념에 익숙하다. 독자가 인공 신경망이나 다른 종류의 감독 학습 방법에 대한 지식이 있다면 9 장은 상당히 쉽게 소화 할 수 있지만 이전 배경없이 읽을 수 있습니다. 책 전체에서 제공되는 연습 문제를 해결하는 것이 좋습니다. 강사 매뉴얼은 강사에게 제공됩니다. 이 자료 및 기타 관련 자료는 인터넷을 통해 제공됩니다.
대부분의 장 끝에는 "서 지적 및 역사적 발제"라는 제목의 절이 있습니다. 여기서 우리는 그 장에서 제시된 아이디어의 출처를 밝히고 더 많은 독서와 지속적인 연구에 대한 지침을 제공하며 관련 역사적 배경을 설명합니다. 이 섹션을 신뢰할 수 있고 완벽하게 만들려고 시도했지만, 우리는 의심의 여지없이 몇 가지 중요한 사전 작업을 생략했습니다. 이를 위해 사과 드리며 후속 판에 대한 수정 및 연장을 환영합니다.

어떤 의미에서 우리는 30 년 동안이 책을 향해 노력해 왔으며 감사 할 사람이 많이 있습니다. 첫째, 우리는이 책에서 제시된 전반적인 관점을 개발하도록 개인적으로 도운 사람들에게 감사드립니다. 해리 클로프 (Harry Klopf). 강화 학습을 되살려 야한다는 것을 인식하도록 도와주었습니다. Chris Watkins, Dimitri Bertsekas, John Tsitsiklis 및 Paul Werbos는 동적 프로그래밍에 대한 관계의 가치를 알 수 있도록 도와주었습니다. 존 무어 (John Moore)와 짐 케호 (Jim Kehoe)는 동물 학습 이론의 통찰력과 영감을 얻었습니다. 적응의 폭과 중요성을 강조한 Oliver Selfridge; Ron Williams, Charles Anderson, Satinder Singh, Sridhar Mahadevan, Steve Bradtke, Bob Crites, Peter Dayan 및 Leem Baird와 같은 수많은 사람들이 기여한 우리 동료 및 학생들에게 더 많은 기회를 제공합니다. Paul Cohen, Paul Utgoff, Martha Steenstrup, Gerry Tesauro, Mike Jordan, Leslie Kaelbling, Andrew Moore, Chris Atkeson, Tom Mitchell, Nils Nilsson, Stuart Russell, Tom Dietterich와의 토론을 통해 우리는보다 풍부한 학습을 ​​할 수있게되었습니다. 톰 딘, 그리고 밥 나렌 드라. 섹션 4.7, 15.1, 15.4, 15.5 및 15.6의 세부 사항을 제공 한 Michael Littman, Gerry Tesauro, Bob Crites, Satinder Singh 및 Wei Zhang에게 감사드립니다. 우리는 과학 연구의 공군 사무소, 국립 과학 재단 (National Science Foundation), GTE 연구소에 오랫동안 원 대한 지원을 해준 것에 감사드립니다.

이 책의 초안을 읽고 Tom Kalt, John Tsitsiklis, Pawel Cichosz, Olle Ga ̈llmo, Chuck Anderson, Stuart Russell, Ben Van Roy, Paul Steenstrup, Paul Cohen 등 많은 사람들에게 감사의 말을 전합니다. 리차드 코긴스, 크리스티나 베르 시노, 존 H. 히트 트, 안드레아스 바벨트, 제이 폰테, 조 벡, 저스 투스 피터, 마르타 스틴 스트 럽, 새틴 드 싱, 토미 야콥 콜라, Dimitri Bertsekas, Torbjo ̈rn Ekman, Christina Bjo ̈rkman, Jakob Carlstr ̈om 및 Olle Palmgren이 있습니다. 끝으로 MIT Press의 챔피언 인 Harry Stanton과 Bob Prior에게 여러면에서 도움을 준 Gwyn Mitchell에게 감사드립니다.